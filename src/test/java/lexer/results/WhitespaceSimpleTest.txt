[Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value=  , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=this, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value= , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=is, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value= , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=a, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value=     , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=test, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value= , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=file, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='newline', pattern='\r\n|\r|\n', literal='', customMatcher=null}, value=
, keepInAST=false], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value=      , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=mark, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value= , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=the, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value= , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=ident, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value= , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=at, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value= , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=start, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value= , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=of, keepInAST=true], Token[lexerDefinition=LexerDefinition{name='whitespace', pattern='( |	)+', literal='', customMatcher=null}, value= , keepInAST=true], Token[lexerDefinition=LexerDefinition{name='identifier', pattern='[a-zA-Z_][a-zA-Z_0-9]*', literal='', customMatcher=null}, value=line, keepInAST=true]]